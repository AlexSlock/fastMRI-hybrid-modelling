{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GrappaNet, one of the great works on MRI reconstruction was published in 2020. We tried to implement it since code was not available.  The paper can be found here https://arxiv.org/pdf/1910.12325v4.pdf\n",
    "\n",
    "Our Dataset is small and acquired with different imaging conditions than fastMRI dataset. This example has been shown for MRIs acquired with 9 coils. Unlike GrappNet paper we have precalculated grappa weights and reused during training. However, Model was trained in eager mode and consumes significant amount of time and GPU Memory for each epoch. We trained our model on 80 GB Apollo GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compatibility issues with tensorflow result in the fact that python==3.6 is required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and Prepare Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import fft \n",
    "from utils import estimate_mdgrappa_kernel, calculate_mask, comp_sub_kspace, comp_img, apply_kernel_weight\n",
    "import math\n",
    "from pathlib import Path\n",
    "from itertools import chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path = '/usr/local/micapollo01/MIC/DATA/SHARED/NYU_FastMRI'\n",
    "dicom_path = os.path.join(download_path,'fastMRI_brain_DICOM')\n",
    "train_path = os.path.join(download_path,'multicoil_train')\n",
    "validation_path = os.path.join(download_path,'multicoil_val')\n",
    "test_path = os.path.join(download_path,'multicoil_test')\n",
    "fully_sampled_test_path = os.path.join(download_path,'multicoil_test_full')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = Path(train_path).glob('**/*')\n",
    "validation_files = Path(validation_path).glob('**/*')\n",
    "test_files = Path(test_path).glob('**/*')\n",
    "fully_sampled_test_files = Path(fully_sampled_test_path).glob('**/*')\n",
    "all_files = chain(training_files, validation_files, test_files, fully_sampled_test_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_data_2 = np.load(\"/home/mvhave7/Results/Preprocessing/exploration/16coil_slice_size_clustered_fastmri_data.npy\", allow_pickle=True)\n",
    "clustered_data_2 = clustered_data_2.item()\n",
    "\n",
    "files_16_640_320 = clustered_data_2[(640,320)]\n",
    "training_files = files_16_640_320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = (32,640,320)\n",
    "#crop_size = (32,320,320)\n",
    "\n",
    "# The size to which each slice is cropped in order to be compatible with GrappaNet\n",
    "# crop_size[0] = nCh x 2 (real and imaginary parts), crop_size[1] = height, crop_size[2] = width\n",
    "\n",
    "# For the knee dataset, height and width would be 320x320 (see GrappaNet paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Grappa Weight for each MRI (K-space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 1\n",
    "last_mask = None\n",
    "X_train = []\n",
    "Y_train = []\n",
    "grappa_wt = []\n",
    "grappa_p = []\n",
    "\n",
    "# Optional:\n",
    "#training_files = training_files[:70]\n",
    "\n",
    "# Iterate over all files in the input directory provided above\n",
    "for mri_f in sorted(training_files):\n",
    "    filename = os.path.basename(mri_f)\n",
    "    filename = filename.replace(\".h5\",\"\")\n",
    "    with h5py.File(mri_f,'r') as f:\n",
    "\n",
    "        k = f['kspace'][()]\n",
    "        sequence = f.attrs['acquisition']\n",
    "        nSL, nCh, nFE, nPE = k.shape\n",
    "        \n",
    "        # Create the subsampled training data. In the GrappaNet paper, they say they performed experiments for R=4 and R=8, but they never mention the number or fraction of ACS lines used...\n",
    "        mask = calculate_mask(nFE,nPE,0.08,4)  # Add you maskfunction here, maybe fastmri's RandomMaskFunc? Does this generate ACS lines?\n",
    "        last_mask = mask\n",
    "        subsampled_k = k*mask\n",
    "       \n",
    "        for slice in range(nSL): \n",
    "            target_img = np.zeros((nCh,nFE,nPE),dtype=np.float)\n",
    "            sub_kspace = np.zeros((nCh*2,nFE,nPE),dtype=np.float)\n",
    "            wt,ps = estimate_mdgrappa_kernel(kspace=subsampled_k[slice,:,:,:],calib=None,kernel_size=(5,5),coil_axis=0) \n",
    "            for iCh in range(nCh):\n",
    "                    target_img[iCh,:,:] = abs(fft.fftshift(fft.ifft2(k[slice,iCh,:,:])))\n",
    "                    sub_kspace[iCh,:,:] = subsampled_k[slice,iCh,:,:].real\n",
    "                    sub_kspace[iCh+nCh,:,:] = subsampled_k[slice,iCh,:,:].imag\n",
    "            X_train.append(list(comp_sub_kspace(sub_kspace,crop_size)))\n",
    "            Y_train.append(list(comp_img(target_img,(crop_size[0]//2,crop_size[1],crop_size[2]))))\n",
    "            grappa_wt.append(wt)\n",
    "            grappa_p.append(ps)\n",
    "        \n",
    "        print(cnt, filename, sequence, nSL, nCh, nFE, nPE, sub_kspace.shape)\n",
    "        cnt += 1\n",
    "\n",
    "# Note: some of the above functions might be replacable by fastmri package functions (see tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the MRIs and estimated weight since it takes long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "Y_train = np.array(Y_train).astype(np.float32)\n",
    "X_train = np.array(X_train).astype(np.float32)\n",
    "\n",
    "path_to_save_mri_data = '/home/mvhave7/Results/Preprocessing/mri/'\n",
    "path_to_save_grappa_data = '/home/mvhave7/Results/Preprocessing/grappa/'\n",
    "\n",
    "np.save(path_to_save_mri_data+\"trainig_data_GrappaNet_16_coils.npy\",X_train)\n",
    "np.save(path_to_save_mri_data+\"trainig_data_GT_GrappaNet_16_colis.npy\",Y_train)\n",
    "\n",
    "with open(path_to_save_grappa_data+'grappa_wt.pickle', 'wb') as handle:\n",
    "    pickle.dump(grappa_wt, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(path_to_save_grappa_data+'grappa_p.pickle', 'wb') as handle:\n",
    "    pickle.dump(grappa_p, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate RSS that will be used as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.transpose(X_train,(0,2,3,1))\n",
    "Y_rss = np.sqrt(np.sum(np.square(Y_train),axis=1))\n",
    "Y_rss = Y_rss.astype(np.float32)\n",
    "print(X_train.shape,Y_rss.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = X_train.shape\n",
    "for i in range(dims[0]):\n",
    "    for j in range(dims[3]):\n",
    "        X_train[i,:,:,j] = X_train[i,:,:,j]/((np.max(X_train[i,:,:,j])-np.min(X_train[i,:,:,j]))+1e-10)\n",
    "\n",
    "for i in range(dims[0]):\n",
    "    Y_rss[i,:,:] = Y_rss[i,:,:]/((np.max(Y_rss[i,:,:])-np.min(Y_rss[i,:,:]))+1e-10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into train and Test.  10% used for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: in our code, we can use the official fastMRI splits for this, which aren't used here now\n",
    "\n",
    "x_train = X_train[0:int(X_train.shape[0]-X_train.shape[0]*0.1),:,:,:]\n",
    "y_train = Y_rss[0:int(X_train.shape[0]-X_train.shape[0]*0.1),:,:]\n",
    "x_test = X_train[int(X_train.shape[0]-X_train.shape[0]*0.1):,:,:,:]\n",
    "y_test = Y_rss[int(X_train.shape[0]-X_train.shape[0]*0.1):,:,:]\n",
    "y_test = np.reshape(y_test, (y_test.shape[0],crop_size[1],crop_size[2]))\n",
    "train_indx = np.array(range(0,int(X_train.shape[0]-X_train.shape[0]*0.1)),dtype=int)\n",
    "test_indx = np.array(range(int(X_train.shape[0]-X_train.shape[0]*0.1),X_train.shape[0]),dtype=int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize a sample to check everything looks ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = 50   # Slice\n",
    "ref_img = abs(fft.fftshift(fft.ifft2(x_train[indx,:,:,:])))\n",
    "\n",
    "fix,ax = plt.subplots(nrows=1,ncols=2,figsize=(6,10))\n",
    "ax[0].imshow(x_train[indx,:,:,0],cmap='gray')\n",
    "ax[1].imshow(Y_rss[indx,:,:],cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model. The precalculated grappa weight will be used to eliminate redundant calculation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "# The garbage collector is a part of the Python runtime that automatically frees up memory that is no longer in use by the program\n",
    "gc.collect()\n",
    "model=None\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import add, Dropout, Lambda, ReLU\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import tensorflow_addons as tfa\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "\n",
    "lamda = 0.001\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def model_loss_ssim(y_true, y_pred):\n",
    "    global lamda\n",
    "    ssim_loss = 0\n",
    "    max_val = 1.0\n",
    "    if tf.reduce_max(y_pred)>1.0:\n",
    "        max_val = tf.reduce_max(y_pred)\n",
    "    ssim_loss = tf.math.abs(tf.reduce_mean(tf.image.ssim(img1=y_true,img2=y_pred,max_val=max_val,filter_size=3,filter_sigma=0.1)))\n",
    "    l1_loss = lamda*tf.reduce_mean(tf.math.abs(y_true-y_pred))\n",
    "    return 1-ssim_loss+l1_loss\n",
    "\n",
    "\n",
    "def conv_block(ip, nfilters, drop_rate):\n",
    "    \n",
    "    layer_top = Conv2D(nfilters,(3,3),padding=\"same\")(ip)\n",
    "\n",
    "    #layer_top = BatchNormalization()(layer_top)\n",
    "    layer_top = tfa.layers.InstanceNormalization(axis=3,center=True, \n",
    "                                                 scale=True,beta_initializer=\"random_uniform\",\n",
    "                                                 gamma_initializer=\"random_uniform\")(layer_top)\n",
    "    res_model = ReLU()(layer_top)\n",
    "    res_model = Dropout(drop_rate)(res_model)\n",
    "    \n",
    "    res_model = Conv2D(nfilters,(3,3),padding=\"same\")(res_model)\n",
    "    res_model = tfa.layers.InstanceNormalization(axis=3, center=True, \n",
    "                                                 scale=True,beta_initializer=\"random_uniform\",\n",
    "                                                 gamma_initializer=\"random_uniform\")(res_model)\n",
    "    #res_model = BatchNormalization()(res_model)\n",
    "    res_model = Dropout(drop_rate)(res_model)\n",
    "    res_model = add([layer_top,res_model])\n",
    "    res_model = ReLU()(res_model)\n",
    "    return res_model\n",
    "\n",
    "\n",
    "def encoder(inp,nlayers, nbasefilters, drop_rate):\n",
    "    \n",
    "    skip_layers = []\n",
    "    layers = inp\n",
    "    for i in range(nlayers):\n",
    "        layers = conv_block(layers,nbasefilters*2**i,drop_rate)\n",
    "        skip_layers.append(layers)\n",
    "        layers = MaxPooling2D((2,2))(layers)\n",
    "    return layers, skip_layers\n",
    "\n",
    "\n",
    "def decoder(inp,nlayers, nbasefilters, skip_layers, drop_rate):\n",
    "    \n",
    "    layers = inp\n",
    "    for i in range(nlayers):\n",
    "        layers = conv_block(layers,nbasefilters*(2**(nlayers-1-i)),drop_rate)\n",
    "        layers = UpSampling2D(size=(2,2),interpolation='bilinear')(layers)\n",
    "        layers = add([layers,skip_layers.pop()])\n",
    "    return layers\n",
    "\n",
    "\n",
    "def create_gen(gen_ip, nlayers, nbasefilters, drop_rate):\n",
    "    op,skip_layers = encoder(gen_ip,nlayers,nbasefilters,drop_rate)\n",
    "    op = decoder(op,nlayers,nbasefilters,skip_layers,drop_rate)\n",
    "    op = Conv2D(crop_size[0],(3,3),padding=\"same\")(op)\n",
    "    return op\n",
    "\n",
    "\n",
    "def custom_data_consistency(tensors):\n",
    "    output = tf.where(tf.greater_equal(tensors[0], 1), tensors[0], tensors[1])\n",
    "    out_cmplx = tf.complex(output[:,:,:,0:(crop_size[0]//2)], output[:,:,:,(crop_size[0]//2):(crop_size[0])])\n",
    "    ift_sig = tf.signal.fftshift(tf.signal.ifft2d(out_cmplx, name=None))\n",
    "    real_p = tf.math.real(ift_sig)\n",
    "    imag_p = tf.math.imag(ift_sig)\n",
    "    comb = tf.concat(axis=-1,values=[real_p, imag_p])\n",
    "    return comb\n",
    "\n",
    "\n",
    "def custom_data_consistency_2(tensors):\n",
    "    out_cmplx = tf.complex(tensors[1][:,:,:,0:(crop_size[0]//2)], tensors[1][:,:,:,(crop_size[0]//2):(crop_size[0])])\n",
    "    ft_sig = tf.signal.fftshift(tf.signal.fft2d(out_cmplx, name=None))\n",
    "    real_p = tf.math.real(ft_sig)\n",
    "    imag_p = tf.math.imag(ft_sig)\n",
    "    comb = tf.concat(axis=-1,values=[real_p, imag_p])\n",
    "    output = tf.where(tf.greater_equal(tensors[0], 1), tensors[0], comb)\n",
    "    return output\n",
    "\n",
    "\n",
    "def aux_Grappa_layer(tensor1, tensor2):\n",
    "    global grappa_wt\n",
    "    global grappa_p\n",
    "    t1 = tensor1.numpy()\n",
    "    t2 = tensor2.numpy()\n",
    "\n",
    "    x_train_cmplx_target = t2[:,:,:,0:(crop_size[0]//2)]+1j*t2[:,:,:,(crop_size[0]//2):(crop_size[0])]\n",
    "    x_train_cmplx_target = np.transpose(x_train_cmplx_target,(0,3,1,2))\n",
    "    l_grappa = []\n",
    "    for i in range(x_train_cmplx_target.shape[0]):\n",
    "        res = apply_kernel_weight(kspace=x_train_cmplx_target[i],calib=None,\n",
    "                                 kernel_size=(5,5),coil_axis=0,\n",
    "                                 weights=grappa_wt[int(t1[i][0])],P=grappa_p[int(t1[i][0])])\n",
    "        res = np.transpose(res,(1,2,0))\n",
    "        out_cmplx_real = tf.convert_to_tensor(res.real)\n",
    "        out_cmplx_imag = tf.convert_to_tensor(res.imag)\n",
    "        comb = tf.concat(axis=2,values=[out_cmplx_real, out_cmplx_imag])\n",
    "        l_grappa.append(comb)\n",
    "    b_grappa = tf.stack(l_grappa)\n",
    "\n",
    "    return b_grappa\n",
    "\n",
    "\n",
    "def Grappa_layer(tensor):\n",
    "    out_tensor = tf.py_function(func=aux_Grappa_layer, inp=tensor, Tout=tf.float32)\n",
    "    out_tensor.set_shape(tensor[1].get_shape())\n",
    "    return out_tensor\n",
    "\n",
    "\n",
    "def ift_RSS(tensor):\n",
    "    cmplx_tensor = tf.complex(tensor[:,:,:,0:(crop_size[0]//2)], tensor[:,:,:,(crop_size[0]//2):(crop_size[0])])\n",
    "    ift_sig = tf.signal.fftshift(tf.signal.ifft2d(cmplx_tensor, name=None))\n",
    "    Y_rss = tf.math.sqrt(tf.math.reduce_sum(tf.square(tf.math.abs(ift_sig)),axis=3))\n",
    "    return Y_rss\n",
    "\n",
    "\n",
    "def build_model(input_shape, n_filter=32, n_depth=4, dropout_rate=0.05):\n",
    "\n",
    "    #first pass\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    input_layer_grappa_wt_indx = Input(shape=(1))\n",
    "    kspace_u1 = create_gen(input_layer,n_depth,n_filter,dropout_rate)\n",
    "    data_con_layer = Lambda(custom_data_consistency, name=\"data_const_K_u1\")([input_layer, kspace_u1])\n",
    "    img_space_u1 = create_gen(data_con_layer,n_depth,n_filter,dropout_rate)\n",
    "    data_con_layer = Lambda(custom_data_consistency_2, name=\"data_const_K_u1_2\")([input_layer, img_space_u1])\n",
    "    grappa_recon_k = Lambda(Grappa_layer, name=\"data_const_K_2\")([input_layer_grappa_wt_indx, data_con_layer])\n",
    "    \n",
    "    #second Pass\n",
    "    kspace_u2 = create_gen(grappa_recon_k,n_depth,n_filter,dropout_rate)\n",
    "    data_con_layer = Lambda(custom_data_consistency, name=\"data_const_K_u2\")([input_layer, kspace_u2])\n",
    "    img_space_u2 = create_gen(data_con_layer,n_depth,n_filter,dropout_rate)\n",
    "    data_con_layer = Lambda(custom_data_consistency_2, name=\"data_const_K_u2_2\")([input_layer, img_space_u2])\n",
    "    \n",
    "    #IFT+RSS\n",
    "    data_con_layer = Lambda(ift_RSS, name=\"IFT_RSS\")(data_con_layer)\n",
    "\n",
    "    return Model(inputs=[input_layer,input_layer_grappa_wt_indx],outputs=data_con_layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model. Model will be trained in eager mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "model_name = \"/home/mvhave7/Results/Models/model_GrappaNet.h5\"\n",
    "\n",
    "\n",
    "def step_decay(epoch, initial_lrate, drop, epochs_drop):\n",
    "    return initial_lrate * math.pow(drop, math.floor((1+epoch)/float(epochs_drop)))\n",
    "\n",
    "def get_callbacks(model_file, learning_rate_drop=0.7, learning_rate_patience=7, verbosity=1):\n",
    "    callbacks = list()\n",
    "    callbacks.append(ModelCheckpoint(model_file, save_best_only=True))\n",
    "    callbacks.append(ReduceLROnPlateau(factor=learning_rate_drop, patience=learning_rate_patience, verbose=verbosity))\n",
    "    callbacks.append(EarlyStopping(verbose=verbosity, patience=200))\n",
    "    return callbacks\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    input_shape = (crop_size[1],crop_size[2],crop_size[0])\n",
    "    epochs = 1\n",
    "    batch_size = 8\n",
    "    model = build_model(input_shape)\n",
    "    metrics = tf.keras.metrics.RootMeanSquaredError()\n",
    "    model.compile(loss=model_loss_ssim, optimizer=Adam(learning_rate=0.0003), metrics=[metrics])\n",
    "    #model.compile(loss=model_loss_ssim, optimizer=RMSprop(learning_rate=0.0003), metrics=[metrics])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([x_train,train_indx], y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            validation_data=([x_test,test_indx], y_test),\n",
    "            callbacks=get_callbacks(model_name,0.6,10,1),\n",
    "            max_queue_size=32,\n",
    "            workers=100,\n",
    "            use_multiprocessing=False\n",
    "             )\n",
    "\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"/home/mvhave7/Results/Models/final_model_GrappaNet.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"/home/mvhave7/Results/Models/final_model_GrappaNet_json.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load an earlier pre-trained model:\n",
    "\n",
    "#from tensorflow.keras.models import load_model\n",
    "\n",
    "#model.load_weights(\"/home/mvhave7/Results/Models/model_GrappaNet.h5\")\n",
    "#ex_recons_imgs = model.predict([x_test,test_indx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
