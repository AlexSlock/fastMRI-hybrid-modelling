{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we can test the performance of a previously trained GrappaNet model on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import fft \n",
    "from utils import apply_kernel_weight\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import add, Dropout, Lambda, ReLU\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import tensorflow_addons as tfa\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "crop_size = (32,640,320)\n",
    "\n",
    "\n",
    "lamda = 0.001\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def model_loss_ssim(y_true, y_pred):\n",
    "    global lamda\n",
    "    ssim_loss = 0\n",
    "    max_val = 1.0\n",
    "    if tf.reduce_max(y_pred)>1.0:\n",
    "        max_val = tf.reduce_max(y_pred)\n",
    "    ssim_loss = tf.math.abs(tf.reduce_mean(tf.image.ssim(img1=y_true,img2=y_pred,max_val=max_val,filter_size=3,filter_sigma=0.1)))\n",
    "    l1_loss = lamda*tf.reduce_mean(tf.math.abs(y_true-y_pred))\n",
    "    return 1-ssim_loss+l1_loss\n",
    "\n",
    "\n",
    "def conv_block(ip, nfilters, drop_rate):\n",
    "    \n",
    "    layer_top = Conv2D(nfilters,(3,3),padding=\"same\")(ip)\n",
    "\n",
    "    #layer_top = BatchNormalization()(layer_top)\n",
    "    layer_top = tfa.layers.InstanceNormalization(axis=3,center=True, \n",
    "                                                 scale=True,beta_initializer=\"random_uniform\",\n",
    "                                                 gamma_initializer=\"random_uniform\")(layer_top)\n",
    "    res_model = ReLU()(layer_top)\n",
    "    res_model = Dropout(drop_rate)(res_model)\n",
    "    \n",
    "    res_model = Conv2D(nfilters,(3,3),padding=\"same\")(res_model)\n",
    "    res_model = tfa.layers.InstanceNormalization(axis=3, center=True, \n",
    "                                                 scale=True,beta_initializer=\"random_uniform\",\n",
    "                                                 gamma_initializer=\"random_uniform\")(res_model)\n",
    "    #res_model = BatchNormalization()(res_model)\n",
    "    res_model = Dropout(drop_rate)(res_model)\n",
    "    res_model = add([layer_top,res_model])\n",
    "    res_model = ReLU()(res_model)\n",
    "    return res_model\n",
    "\n",
    "\n",
    "def encoder(inp,nlayers, nbasefilters, drop_rate):\n",
    "    \n",
    "    skip_layers = []\n",
    "    layers = inp\n",
    "    for i in range(nlayers):\n",
    "        layers = conv_block(layers,nbasefilters*2**i,drop_rate)\n",
    "        skip_layers.append(layers)\n",
    "        layers = MaxPooling2D((2,2))(layers)\n",
    "    return layers, skip_layers\n",
    "\n",
    "\n",
    "def decoder(inp,nlayers, nbasefilters, skip_layers, drop_rate):\n",
    "    \n",
    "    layers = inp\n",
    "    for i in range(nlayers):\n",
    "        layers = conv_block(layers,nbasefilters*(2**(nlayers-1-i)),drop_rate)\n",
    "        layers = UpSampling2D(size=(2,2),interpolation='bilinear')(layers)\n",
    "        layers = add([layers,skip_layers.pop()])\n",
    "    return layers\n",
    "\n",
    "\n",
    "def create_gen(gen_ip, nlayers, nbasefilters, drop_rate):\n",
    "    op,skip_layers = encoder(gen_ip,nlayers,nbasefilters,drop_rate)\n",
    "    op = decoder(op,nlayers,nbasefilters,skip_layers,drop_rate)\n",
    "    op = Conv2D(crop_size[0],(3,3),padding=\"same\")(op)\n",
    "    return op\n",
    "\n",
    "\n",
    "def custom_data_consistency(tensors):\n",
    "    output = tf.where(tf.greater_equal(tensors[0], 1), tensors[0], tensors[1])\n",
    "    out_cmplx = tf.complex(output[:,:,:,0:(crop_size[0]//2)], output[:,:,:,(crop_size[0]//2):(crop_size[0])])\n",
    "    ift_sig = tf.signal.fftshift(tf.signal.ifft2d(out_cmplx, name=None))\n",
    "    real_p = tf.math.real(ift_sig)\n",
    "    imag_p = tf.math.imag(ift_sig)\n",
    "    comb = tf.concat(axis=-1,values=[real_p, imag_p])\n",
    "    return comb\n",
    "\n",
    "\n",
    "def custom_data_consistency_2(tensors):\n",
    "    out_cmplx = tf.complex(tensors[1][:,:,:,0:(crop_size[0]//2)], tensors[1][:,:,:,(crop_size[0]//2):(crop_size[0])])\n",
    "    ft_sig = tf.signal.fftshift(tf.signal.fft2d(out_cmplx, name=None))\n",
    "    real_p = tf.math.real(ft_sig)\n",
    "    imag_p = tf.math.imag(ft_sig)\n",
    "    comb = tf.concat(axis=-1,values=[real_p, imag_p])\n",
    "    output = tf.where(tf.greater_equal(tensors[0], 1), tensors[0], comb)\n",
    "    return output\n",
    "\n",
    "\n",
    "def aux_Grappa_layer(tensor1, tensor2):\n",
    "    global grappa_wt\n",
    "    global grappa_p\n",
    "    t1 = tensor1.numpy()\n",
    "    t2 = tensor2.numpy()\n",
    "\n",
    "    x_train_cmplx_target = t2[:,:,:,0:(crop_size[0]//2)]+1j*t2[:,:,:,(crop_size[0]//2):(crop_size[0])]\n",
    "    x_train_cmplx_target = np.transpose(x_train_cmplx_target,(0,3,1,2))\n",
    "    l_grappa = []\n",
    "    for i in range(x_train_cmplx_target.shape[0]):\n",
    "        res = apply_kernel_weight(kspace=x_train_cmplx_target[i],calib=None,\n",
    "                                 kernel_size=(5,5),coil_axis=0,\n",
    "                                 weights=grappa_wt[int(t1[i][0])],P=grappa_p[int(t1[i][0])])\n",
    "        res = np.transpose(res,(1,2,0))\n",
    "        out_cmplx_real = tf.convert_to_tensor(res.real)\n",
    "        out_cmplx_imag = tf.convert_to_tensor(res.imag)\n",
    "        comb = tf.concat(axis=2,values=[out_cmplx_real, out_cmplx_imag])\n",
    "        l_grappa.append(comb)\n",
    "    b_grappa = tf.stack(l_grappa)\n",
    "\n",
    "    return b_grappa\n",
    "\n",
    "\n",
    "def Grappa_layer(tensor):\n",
    "    out_tensor = tf.py_function(func=aux_Grappa_layer, inp=tensor, Tout=tf.float32)\n",
    "    out_tensor.set_shape(tensor[1].get_shape())\n",
    "    return out_tensor\n",
    "\n",
    "\n",
    "def ift_RSS(tensor):\n",
    "    cmplx_tensor = tf.complex(tensor[:,:,:,0:(crop_size[0]//2)], tensor[:,:,:,(crop_size[0]//2):(crop_size[0])])\n",
    "    ift_sig = tf.signal.fftshift(tf.signal.ifft2d(cmplx_tensor, name=None))\n",
    "    Y_rss = tf.math.sqrt(tf.math.reduce_sum(tf.square(tf.math.abs(ift_sig)),axis=3))\n",
    "    return Y_rss\n",
    "\n",
    "\n",
    "def build_model(input_shape, n_filter=32, n_depth=4, dropout_rate=0.05):\n",
    "\n",
    "    #first pass\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    input_layer_grappa_wt_indx = Input(shape=(1))\n",
    "    kspace_u1 = create_gen(input_layer,n_depth,n_filter,dropout_rate)\n",
    "    data_con_layer = Lambda(custom_data_consistency, name=\"data_const_K_u1\")([input_layer, kspace_u1])\n",
    "    img_space_u1 = create_gen(data_con_layer,n_depth,n_filter,dropout_rate)\n",
    "    data_con_layer = Lambda(custom_data_consistency_2, name=\"data_const_K_u1_2\")([input_layer, img_space_u1])\n",
    "    grappa_recon_k = Lambda(Grappa_layer, name=\"data_const_K_2\")([input_layer_grappa_wt_indx, data_con_layer])\n",
    "    \n",
    "    #second Pass\n",
    "    kspace_u2 = create_gen(grappa_recon_k,n_depth,n_filter,dropout_rate)\n",
    "    data_con_layer = Lambda(custom_data_consistency, name=\"data_const_K_u2\")([input_layer, kspace_u2])\n",
    "    img_space_u2 = create_gen(data_con_layer,n_depth,n_filter,dropout_rate)\n",
    "    data_con_layer = Lambda(custom_data_consistency_2, name=\"data_const_K_u2_2\")([input_layer, img_space_u2])\n",
    "    \n",
    "    #IFT+RSS\n",
    "    data_con_layer = Lambda(ift_RSS, name=\"IFT_RSS\")(data_con_layer)\n",
    "\n",
    "    return Model(inputs=[input_layer,input_layer_grappa_wt_indx],outputs=data_con_layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('/usr/local/micapollo01/MIC/DATA/STUDENTS/mvhave7/Results/Models/best_model_GrappaNet.h5', custom_objects={'model_loss_ssim': model_loss_ssim})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "download_path = '/usr/local/micapollo01/MIC/DATA/SHARED/NYU_FastMRI'\n",
    "test_path = os.path.join(download_path,'multicoil_test')\n",
    "test_target_path = os.path.join(download_path,'multicoil_test_full')\n",
    "file_name = 'file_brain_AXFLAIR_200_6002441.h5'\n",
    "\n",
    "hf_test = h5py.File(os.path.join(test_path, file_name))\n",
    "hf_test_target = h5py.File(os.path.join(test_target_path, file_name))\n",
    "\n",
    "test_volume_kspace = hf_test['kspace'][()]\n",
    "test_target_volume_kspace = hf_test_target['kspace'][()]\n",
    "test_target_volume_image = np.sqrt(np.sum(np.square(test_target_volume_kspace),axis=1)).astype(np.float32)\n",
    "\n",
    "\n",
    "# Normalize the test data\n",
    "dims = test_volume_kspace.shape\n",
    "for i in range(dims[0]):\n",
    "   for j in range(dims[1]):\n",
    "       test_volume_kspace[i,:,:,j] = test_volume_kspace[i,:,:,j]/((np.max(test_volume_kspace[i,:,:,j])-np.min(test_volume_kspace[i,:,:,j]))+1e-10)\n",
    "\n",
    "for i in range(dims[0]):\n",
    "    test_target_volume_image[i,:,:] = test_target_volume_image[i,:,:]/((np.max(test_target_volume_image[i,:,:])-np.min(test_target_volume_image[i,:,:]))+1e-10)\n",
    "\n",
    "\n",
    "# Choose a slice to test performance on\n",
    "slice = 10\n",
    "test_slice_kspace = test_volume_kspace[slice,:,:,:]\n",
    "test_target_slice_image = test_target_volume_image[slice,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_coils(data, slice_nums, cmap=None):\n",
    "    fig = plt.figure()\n",
    "    for i, num in enumerate(slice_nums):\n",
    "        plt.subplot(1, len(slice_nums), i + 1)\n",
    "        plt.imshow(data[num], cmap=cmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_coils(np.log(np.abs(test_slice_kspace) + 1e-9), [0, 5, 10], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_target_slice_image,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_slice_kspace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the data to get the correct dimensions\n",
    "\n",
    "test_slice_kspace = np.transpose(test_slice_kspace,(1,2,0))\n",
    "\n",
    "test_slice_kspace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction with our model\n",
    "\n",
    "reconstructed_test_image = model.predict(test_slice_kspace)\n",
    "\n",
    "plt.imshow(reconstructed_test_image,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(actual, pred): \n",
    "   actual, pred = np.array(actual), np.array(pred)\n",
    "   return np.square(np.subtract(actual,pred)).mean()\n",
    "\n",
    "def nmse(actual, pred):\n",
    "   mse_result = mse(actual, pred)\n",
    "   return mse_result/(np.square(actual).mean())\n",
    "\n",
    "nmse_reconstruction = nmse(test_target_slice_image,reconstructed_test_image)\n",
    "print(nmse_reconstruction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_MRI_reconstruction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
