{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_mri_data = '/usr/local/micapollo01/MIC/DATA/STUDENTS/mvhave7/Results/Preprocessing/mri/'\n",
    "path_to_save_grappa_data = '/usr/local/micapollo01/MIC/DATA/STUDENTS/mvhave7/Results/Preprocessing/grappa/'\n",
    "\n",
    "\n",
    "file_paths_train = sorted(glob.glob(path_to_save_mri_data+\"training_data_GrappaNet_16_coils_batch_*.npy\"))[50]\n",
    "file_paths_train_GT = sorted(glob.glob(path_to_save_mri_data+\"training_data_GT_GrappaNet_16_colis_batch_*.npy\"))[50]\n",
    "file_paths_val = sorted(glob.glob(path_to_save_mri_data+\"validation_data_GrappaNet_16_coils_batch_*.npy\"))[50]\n",
    "file_paths_val_GT = sorted(glob.glob(path_to_save_mri_data+\"validation_data_GT_GrappaNet_16_colis_batch_*.npy\"))[50]\n",
    "file_paths_grappa_indx_train = sorted(glob.glob(path_to_save_grappa_data+\"grappa_train_indx_GrappaNet_16_coils_batch_*.npy\"))[50]\n",
    "file_paths_grappa_indx_val = sorted(glob.glob(path_to_save_grappa_data+\"grappa_test_indx_GrappaNet_16_colis_batch_*.npy\"))[50]\n",
    "file_paths_grappa_wt = sorted(glob.glob(path_to_save_grappa_data+\"grappa_wt_batch_*.pickle\"))[50]\n",
    "file_paths_grappa_p = sorted(glob.glob(path_to_save_grappa_data+\"grappa_p_batch_*.pickle\"))[50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(file_paths_train)\n",
    "y_train = np.load(file_paths_train_GT)\n",
    "grappa_train_indx = np.load(file_paths_grappa_indx_train)\n",
    "with open(file_paths_grappa_wt, 'rb') as handle:\n",
    "    grappa_wt = pickle.load(handle)\n",
    "with open(file_paths_grappa_p, 'rb') as handle:\n",
    "    grappa_p = pickle.load(handle)\n",
    "x_test = np.load(file_paths_val)\n",
    "y_test = np.load(file_paths_val_GT)\n",
    "grappa_test_indx = np.load(file_paths_grappa_indx_val)\n",
    "with open(file_paths_grappa_wt, 'rb') as handle:\n",
    "    grappa_wt = pickle.load(handle)\n",
    "with open(file_paths_grappa_p, 'rb') as handle:\n",
    "    grappa_p = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "float32\n",
      "int64\n",
      "int64\n",
      "float32\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(x_train.dtype)\n",
    "print(y_train.dtype)\n",
    "print(grappa_train_indx.dtype)\n",
    "print(grappa_test_indx.dtype)\n",
    "print(x_test.dtype)\n",
    "print(y_test.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138, 640, 320, 32)\n",
      "(138, 640, 320)\n",
      "(138,)\n",
      "(16,)\n",
      "(16, 640, 320, 32)\n",
      "(16, 640, 320)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(grappa_train_indx.shape)\n",
    "print(grappa_test_indx.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "print(type(y_train))\n",
    "print(type(grappa_train_indx))\n",
    "print(type(grappa_test_indx))\n",
    "print(type(x_test))\n",
    "print(type(y_test))\n",
    "print(type(grappa_wt))\n",
    "print(type(grappa_p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the above data properties with the data properties of the variables when they were originally preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, os\n",
    "import numpy as np\n",
    "from numpy import fft \n",
    "import matplotlib.pyplot as plt\n",
    "from utils import estimate_mdgrappa_kernel, calculate_mask, comp_sub_kspace, comp_img\n",
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "import gc\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "clustered_data_2 = np.load(\"/usr/local/micapollo01/MIC/DATA/STUDENTS/mvhave7/Results/Preprocessing/exploration/16coil_slice_size_clustered_fastmri_data.npy\", allow_pickle=True)\n",
    "clustered_data_2 = clustered_data_2.item()\n",
    "\n",
    "files_16_640_320 = clustered_data_2[(640,320)]\n",
    "training_files = sorted(files_16_640_320)\n",
    "\n",
    "crop_size = (32,640,320)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dataset construction and GRAPPA kernel estimation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mvhave7/GitLab/master_thesis/GrappaNet/model_v2/utils.py:97: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  np.array(pads, dtype=np.uintp), lamda)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 file_brain_AXFLAIR_200_6002435 AXFLAIR 16 16 640 320 (32, 640, 320)\n",
      "2 file_brain_AXFLAIR_200_6002442 AXFLAIR 16 16 640 320 (32, 640, 320)\n",
      "Done. Calculating RSS images as references for the loss function...\n",
      "(32, 640, 320, 32) (32, 640, 320)\n",
      "Done. Normalizing the data...\n",
      "Done. Performing a datasplit...\n",
      "Done. Checking data specs of the results...\n",
      "float32\n",
      "float32\n",
      "int64\n",
      "int64\n",
      "float32\n",
      "float32\n",
      "(28, 640, 320, 32)\n",
      "(28, 640, 320)\n",
      "(28,)\n",
      "(4,)\n",
      "(4, 640, 320, 32)\n",
      "(4, 640, 320)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "## Pick a small batch to view the data properties after the original preprocessing process is done\n",
    "\n",
    "remaining_files = training_files[0:2]\n",
    "\n",
    "\n",
    "## Create training data pairs and estimate GRAPPA kernels\n",
    "\n",
    "print('Starting dataset construction and GRAPPA kernel estimation...')\n",
    "\n",
    "cnt = 1\n",
    "last_mask = None\n",
    "X_train = []\n",
    "Y_train = []\n",
    "grappa_wt = []\n",
    "grappa_p = []\n",
    "\n",
    "for mri_f in remaining_files:\n",
    "    filename = os.path.basename(mri_f)\n",
    "    filename = filename.replace(\".h5\",\"\")\n",
    "    with h5py.File(mri_f,'r') as f:\n",
    "\n",
    "        k = f['kspace'][()]\n",
    "        sequence = f.attrs['acquisition']\n",
    "        nSL, nCh, nFE, nPE = k.shape\n",
    "            \n",
    "        # Create the subsampled training data. In the GrappaNet paper, they say they performed experiments for R=4 and R=8, but they never mention the number or fraction of ACS lines used...\n",
    "        mask = calculate_mask(nFE,nPE,0.08,4)\n",
    "        last_mask = mask\n",
    "        subsampled_k = k*mask\n",
    "        \n",
    "        for slice in range(nSL): \n",
    "            target_img = np.zeros((nCh,nFE,nPE),dtype=np.float)\n",
    "            sub_kspace = np.zeros((nCh*2,nFE,nPE),dtype=np.float)\n",
    "            wt,ps = estimate_mdgrappa_kernel(kspace=subsampled_k[slice,:,:,:],calib=None,kernel_size=(5,5),coil_axis=0) \n",
    "            for iCh in range(nCh):\n",
    "                    target_img[iCh,:,:] = abs(fft.fftshift(fft.ifft2(k[slice,iCh,:,:])))\n",
    "                    sub_kspace[iCh,:,:] = subsampled_k[slice,iCh,:,:].real\n",
    "                    sub_kspace[iCh+nCh,:,:] = subsampled_k[slice,iCh,:,:].imag\n",
    "            X_train.append(list(comp_sub_kspace(sub_kspace,crop_size)))\n",
    "            Y_train.append(list(comp_img(target_img,(crop_size[0]//2,crop_size[1],crop_size[2]))))\n",
    "            grappa_wt.append(wt)\n",
    "            grappa_p.append(ps)\n",
    "          \n",
    "        print(cnt,filename,sequence,nSL,nCh,nFE,nPE,sub_kspace.shape)\n",
    "        cnt += 1\n",
    "\n",
    "Y_train = np.array(Y_train).astype(np.float32)\n",
    "X_train = np.array(X_train).astype(np.float32)\n",
    "\n",
    "\n",
    "print('Done. Calculating RSS images as references for the loss function...')\n",
    "\n",
    "\n",
    "## Calculate RSS images that will be used as references for the loss function\n",
    "\n",
    "X_train = np.transpose(X_train,(0,2,3,1))\n",
    "Y_rss = np.sqrt(np.sum(np.square(Y_train),axis=1))\n",
    "Y_rss = Y_rss.astype(np.float32)\n",
    "print(X_train.shape,Y_rss.shape)\n",
    "\n",
    "\n",
    "print('Done. Normalizing the data...')\n",
    "\n",
    "\n",
    "## Normalize the data\n",
    "\n",
    "dims = X_train.shape\n",
    "for i in range(dims[0]):\n",
    "    for j in range(dims[3]):\n",
    "        X_train[i,:,:,j] = X_train[i,:,:,j]/((np.max(X_train[i,:,:,j])-np.min(X_train[i,:,:,j]))+1e-10)\n",
    "\n",
    "for i in range(dims[0]):\n",
    "    Y_rss[i,:,:] = Y_rss[i,:,:]/((np.max(Y_rss[i,:,:])-np.min(Y_rss[i,:,:]))+1e-10)\n",
    "\n",
    "\n",
    "print('Done. Performing a datasplit...')\n",
    "\n",
    "\n",
    "## Create a dataset split 90-10 training-validation\n",
    "\n",
    "x_train = X_train[0:int(X_train.shape[0]-X_train.shape[0]*0.1),:,:,:]\n",
    "y_train = Y_rss[0:int(X_train.shape[0]-X_train.shape[0]*0.1),:,:]\n",
    "x_test = X_train[int(X_train.shape[0]-X_train.shape[0]*0.1):,:,:,:]\n",
    "y_test = Y_rss[int(X_train.shape[0]-X_train.shape[0]*0.1):,:,:]\n",
    "y_test = np.reshape(y_test, (y_test.shape[0],crop_size[1],crop_size[2]))\n",
    "grappa_train_indx = np.array(range(0,int(X_train.shape[0]-X_train.shape[0]*0.1)),dtype=int)\n",
    "grappa_test_indx = np.array(range(int(X_train.shape[0]-X_train.shape[0]*0.1),X_train.shape[0]),dtype=int)\n",
    "\n",
    "\n",
    "print('Done. Checking data specs of the results...')\n",
    "\n",
    "\n",
    "print(x_train.dtype)\n",
    "print(y_train.dtype)\n",
    "print(grappa_train_indx.dtype)\n",
    "print(grappa_test_indx.dtype)\n",
    "print(x_test.dtype)\n",
    "print(y_test.dtype)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(grappa_train_indx.shape)\n",
    "print(grappa_test_indx.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(type(x_train))\n",
    "print(type(y_train))\n",
    "print(type(grappa_train_indx))\n",
    "print(type(grappa_test_indx))\n",
    "print(type(x_test))\n",
    "print(type(y_test))\n",
    "print(type(grappa_wt))\n",
    "print(type(grappa_p))\n",
    "\n",
    "\n",
    "print('Done.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_MRI_reconstruction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
